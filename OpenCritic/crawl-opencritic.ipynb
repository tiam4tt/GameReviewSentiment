{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "# URL of the main sitemap\n",
    "sitemap_url = 'https://opencritic.com/sitemap.xml'\n",
    "\n",
    "# Function to retrieve all sitemap links from the main sitemap\n",
    "def get_sitemap_links(sitemap_url):\n",
    "    response = requests.get(sitemap_url)\n",
    "    if response.status_code == 200:  # Check if the request was successful\n",
    "        root = ET.fromstring(response.content)\n",
    "        namespaces = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "        # Extract links to specific game sitemaps\n",
    "        sitemap_links = [elem.text for elem in root.findall('.//ns:loc', namespaces) if 'sitemap_games' in elem.text]\n",
    "        return sitemap_links\n",
    "    else:\n",
    "        print(f\"Could not retrieve sitemap. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Function to retrieve game links from a specific sitemap\n",
    "def get_game_links_from_sitemap(sitemap_link):\n",
    "    response = requests.get(sitemap_link)\n",
    "    if response.status_code == 200:  # Check if the request was successful\n",
    "        root = ET.fromstring(response.content)\n",
    "        namespaces = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "        # Extract all game links from the sitemap\n",
    "        game_links = [elem.text for elem in root.findall('.//ns:loc', namespaces)]\n",
    "        # Filter out unwanted links (e.g., \"/media\" or \"/reviews\")\n",
    "        filtered_game_links = [link for link in game_links if \"/media\" not in link and \"/reviews\" not in link]\n",
    "        return filtered_game_links\n",
    "    else:\n",
    "        print(f\"Could not retrieve sitemap: {sitemap_link}. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Function to parse data from a game page\n",
    "def parse_game_page(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract the game title\n",
    "        title = soup.find('h1', class_='my-2 my-md-4').get_text(strip=True) if soup.find('h1', class_='my-2 my-md-4') else \"n/a\"\n",
    "        \n",
    "        # Extract the game genre\n",
    "        genre_tag = soup.find(text=\"Genre\")\n",
    "        genre = genre_tag.find_next().get_text(strip=True) if genre_tag else \"n/a\"\n",
    "        \n",
    "        # Extract pricing information\n",
    "        pricing_tag = soup.find(text=\"Price\")\n",
    "        pricing = pricing_tag.find_next().get_text(strip=True) if pricing_tag else \"n/a\"\n",
    "        \n",
    "        # Extract library size\n",
    "        library_size_tag = soup.find(text=\"Storage\")\n",
    "        library_size = library_size_tag.find_next().get_text(strip=True) if library_size_tag else \"n/a\"\n",
    "        \n",
    "        # Extract publisher information\n",
    "        companies = soup.find('div', {'class': 'companies'})\n",
    "        publisher_tag = companies.find_all('span') if companies else None\n",
    "        publisher = [tag.get_text(strip=True) for tag in publisher_tag] if publisher_tag else \"n/a\"\n",
    "        \n",
    "        # Extract platform information\n",
    "        platform_div = soup.find('div', {'class': 'platforms'})\n",
    "        platform_tag = platform_div.find_all('span') if platform_div else None\n",
    "        platform = [tag.get_text(strip=True) for tag in platform_tag] if platform_tag else \"n/a\"\n",
    "        \n",
    "        # Extract release date\n",
    "        release_date = \"n/a\"\n",
    "        if platform_div and \"Release Date:\" in platform_div.get_text():\n",
    "            release_text = platform_div.get_text(strip=True).replace(\"Release Date:\", \"\").strip()\n",
    "            release_date = release_text.split('-')[0].strip()\n",
    "        \n",
    "        # Extract rating\n",
    "        rating_tag = soup.find('div', class_=\"inner-orb\")\n",
    "        rating = rating_tag.get_text(strip=True) if rating_tag else \"n/a\"\n",
    "        \n",
    "        # Extract number of reviews\n",
    "        reviews_tag = soup.find('a', href=lambda href: href and \"/reviews\" in href)\n",
    "        if reviews_tag:\n",
    "            match = re.search(r'\\d+', reviews_tag.get_text())\n",
    "            num_reviews = int(match.group()) if match else \"n/a\"\n",
    "        else:\n",
    "            num_reviews = \"n/a\"\n",
    "        \n",
    "        # Return parsed data as a dictionary\n",
    "        return {\n",
    "            \"Game Title\": title,\n",
    "            \"Game Genre\": genre,\n",
    "            \"Pricing\": pricing,\n",
    "            \"Game Library Size\": library_size,\n",
    "            \"Publisher\": publisher,\n",
    "            \"Release Date\": release_date,\n",
    "            \"Platform\": platform,\n",
    "            \"Rating\": rating,\n",
    "            \"Number of Rating\": num_reviews\n",
    "        }\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 1: Retrieve all sitemap links\n",
    "sitemap_links = get_sitemap_links(sitemap_url)\n",
    "\n",
    "# Step 2: Get game links from the first sitemap\n",
    "game_links = get_game_links_from_sitemap(sitemap_links[0])\n",
    "\n",
    "# Step 3: Parse each game page to extract information\n",
    "games_data = []\n",
    "for link in game_links:\n",
    "    game_data = parse_game_page(link)\n",
    "    if game_data and game_data['Game Title'] != \"n/a\":  # Only include valid data\n",
    "        games_data.append(game_data)\n",
    "\n",
    "# Step 4: Convert parsed data into a DataFrame\n",
    "df_games = pd.DataFrame(games_data)\n",
    "\n",
    "# Step 5: Drop rows with all missing values\n",
    "df_games = df_games.dropna(how='all')\n",
    "\n",
    "# Step 6: Save the data to a CSV file\n",
    "df_games.to_csv('game_data.csv', index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of the Code\n",
    "\n",
    "## **Imports**\n",
    "- **`requests`**: Used for making HTTP requests to retrieve web pages or XML sitemaps.\n",
    "- **`BeautifulSoup` (from `bs4`)**: Used to parse and extract data from HTML content.\n",
    "- **`pandas`**: Used to organize extracted data into a structured format (DataFrame) for analysis and storage.\n",
    "- **`xml.etree.ElementTree`**: Used to parse and navigate XML files (like sitemaps).\n",
    "- **`re`**: Used for regular expressions, especially to extract numeric patterns (e.g., number of reviews).\n",
    "\n",
    "---\n",
    "\n",
    "## **Constants**\n",
    "- **`sitemap_url`**:\n",
    "  - Points to the main sitemap of `opencritic.com`.\n",
    "  - This sitemap is an XML file containing links to sub-sitemaps or specific web pages.\n",
    "\n",
    "---\n",
    "\n",
    "## **Functions**\n",
    "\n",
    "### **1. `get_sitemap_links`**\n",
    "- **Purpose**: Extract links to all sub-sitemaps related to games from the main sitemap.\n",
    "- **Logic**:\n",
    "  1. Sends a GET request to `sitemap_url`.\n",
    "  2. Checks if the request was successful (`status_code == 200`).\n",
    "  3. Parses the XML content using `ElementTree`.\n",
    "  4. Finds all `<loc>` tags using XML namespaces.\n",
    "  5. Filters the links to only include those containing `'sitemap_games'`.\n",
    "- **Returns**: A list of URLs pointing to game-related sitemaps.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. `get_game_links_from_sitemap`**\n",
    "- **Purpose**: Extract individual game page links from a specific game-related sitemap.\n",
    "- **Logic**:\n",
    "  1. Sends a GET request to a sitemap URL.\n",
    "  2. Parses the XML content and extracts all `<loc>` tags.\n",
    "  3. Filters out unwanted URLs containing `/media` or `/reviews`.\n",
    "- **Returns**: A list of URLs pointing to game pages.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. `parse_game_page`**\n",
    "- **Purpose**: Extract detailed information about a game from its webpage.\n",
    "- **Logic**:\n",
    "  1. Sends a GET request to the game page URL.\n",
    "  2. Parses the HTML using `BeautifulSoup`.\n",
    "  3. Extracts specific details:\n",
    "     - **Title**: From `<h1>` with specific classes.\n",
    "     - **Genre**: Finds the text \"Genre\" and retrieves the following element.\n",
    "     - **Pricing**: Finds the text \"Price\" and retrieves the following element.\n",
    "     - **Library Size**: Finds the text \"Storage\" and retrieves the following element.\n",
    "     - **Publisher**: Extracts all publishers listed under the `companies` section.\n",
    "     - **Platform**: Extracts platforms listed under the `platforms` section.\n",
    "     - **Release Date**: Extracts the release date if mentioned in the `platforms` section.\n",
    "     - **Rating**: Extracts the numeric rating from a specific class.\n",
    "     - **Number of Reviews**: Searches for the `/reviews` link and uses a regex to find numbers.\n",
    "  4. Handles errors during requests or parsing.\n",
    "- **Returns**: A dictionary containing the extracted game data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Main Logic**\n",
    "\n",
    "### **Step 1: Retrieve Sitemap Links**\n",
    "- Calls `get_sitemap_links` to fetch all game-related sitemap URLs.\n",
    "\n",
    "### **Step 2: Retrieve Game Links**\n",
    "- Uses the first sitemap URL from Step 1.\n",
    "- Calls `get_game_links_from_sitemap` to extract all game page URLs.\n",
    "\n",
    "### **Step 3: Parse Game Pages**\n",
    "- Iterates over each game URL from Step 2.\n",
    "- Calls `parse_game_page` to extract game details.\n",
    "- Filters out games with missing titles (`\"n/a\"`).\n",
    "\n",
    "### **Step 4: Create a DataFrame**\n",
    "- Converts the list of dictionaries (`games_data`) into a Pandas DataFrame.\n",
    "\n",
    "### **Step 5: Drop Missing Rows**\n",
    "- Removes rows where all fields are `NaN` using `dropna`.\n",
    "\n",
    "### **Step 6: Save to CSV**\n",
    "- Exports the DataFrame to a CSV file named `game_data.csv`.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
