{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 32808 samples\n",
      "Validation set size: 4101 samples\n",
      "Test set size: 4101 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Create 'is_paid' feature: 0 for free, 1 for paid\n",
    "data['is_paid'] = data['Pricing'].apply(lambda x: 0 if x == 0.0 else 1)\n",
    "\n",
    "# Extract 'Month' from 'Release Date'\n",
    "data['Release Date'] = pd.to_datetime(data['Release Date'], errors='coerce')\n",
    "data['Release Month'] = data['Release Date'].dt.month\n",
    "\n",
    "# Filter to only paid games (is_paid == 1)\n",
    "data_paid = data[data['is_paid'] == 1].reset_index(drop=True)\n",
    "\n",
    "# Select features and target\n",
    "features = ['Game Genre', 'Developer', 'Release Month', 'Pricing']\n",
    "target = 'Rating'\n",
    "\n",
    "X = data_paid[features]\n",
    "y = data_paid[target]\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Game Genre', 'Developer']\n",
    "numerical_features = ['Release Month', 'Pricing']\n",
    "\n",
    "# Preprocessing pipelines for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing to the features\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert the preprocessed features to a DataFrame\n",
    "encoded_cat_features = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "encoded_num_features = numerical_features\n",
    "all_features = list(encoded_cat_features) + encoded_num_features\n",
    "\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed.toarray(), columns=all_features)\n",
    "\n",
    "# Reset the index of X_preprocessed_df to align with y\n",
    "X_preprocessed_df = X_preprocessed_df.reset_index(drop=True)\n",
    "\n",
    "# Split data into training and temporary sets (80% train, 20% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_preprocessed_df, y, test_size=0.2, random_state=18\n",
    ")\n",
    "\n",
    "# Split temporary set into validation and test sets (50% each of temp -> 10% each of original)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=18\n",
    ")\n",
    "\n",
    "# Display the sizes of the splits\n",
    "print(f'Training set size: {X_train.shape[0]} samples')\n",
    "print(f'Validation set size: {X_valid.shape[0]} samples')\n",
    "print(f'Test set size: {X_test.shape[0]} samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Parameter Grids for Regression Models\n",
    "import itertools\n",
    "# Parameter grids for each model\n",
    "param_grids = {\n",
    "    'Ridge': {\n",
    "        'fit_intercept': [True, False],\n",
    "        'normalize': [True, False],\n",
    "        'alpha': [0.1, 1]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'epsilon': [0.1, 0.2],\n",
    "        'max_iter': [300, 500]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Hàm cross-validation cho hồi quy\n",
    "def cross_validate_regression(model, X, y, k=5):\n",
    "    fold_size = len(X) // k\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    scores = {'mse': [], 'rmse': [], 'r2': []}\n",
    "    \n",
    "    for fold in range(k):\n",
    "        start = fold * fold_size\n",
    "        end = start + fold_size if fold != k-1 else len(X)\n",
    "        val_indices = indices[start:end]\n",
    "        train_indices = np.concatenate([indices[:start], indices[end:]])\n",
    "        \n",
    "        # Convert X và y thành numpy arrays nếu là pandas DataFrame hoặc Series\n",
    "        if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.DataFrame, pd.Series)):\n",
    "            y = y.values\n",
    "        \n",
    "        X_train_cv, y_train_cv = X[train_indices], y[train_indices]\n",
    "        X_val_cv, y_val_cv = X[val_indices], y[val_indices]\n",
    "        \n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = model.predict(X_val_cv)\n",
    "        \n",
    "        mse = mean_squared_error(y_val_cv, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_val_cv, y_pred)\n",
    "        \n",
    "        scores['mse'].append(mse)\n",
    "        scores['rmse'].append(rmse)\n",
    "        scores['r2'].append(r2)\n",
    "        \n",
    "    avg_scores = {metric: np.mean(values) for metric, values in scores.items()}\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([22360, 14755,  4851, 29398, 27381, 23040,  1611, 29109, 30680, 17118,\\n       ...\\n        7823,   657, 12932,  5455, 22938,  9876, 25378, 12481, 25907, 16966],\\n      dtype='int32', length=26247)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fit_intercept \u001b[38;5;129;01min\u001b[39;00m param_grids[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinearRegression\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_intercept\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     12\u001b[0m     model \u001b[38;5;241m=\u001b[39m LinearRegression(\n\u001b[0;32m     13\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39mfit_intercept\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# 'normalize' parameter removed\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     )\n\u001b[1;32m---> 16\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     avg_r2 \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m     lr_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_intercept\u001b[39m\u001b[38;5;124m'\u001b[39m: fit_intercept,\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_r2\n\u001b[0;32m     21\u001b[0m     })\n",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m, in \u001b[0;36mcross_validate_regression\u001b[1;34m(model, X, y, k)\u001b[0m\n\u001b[0;32m     13\u001b[0m val_indices \u001b[38;5;241m=\u001b[39m indices[start:end]\n\u001b[0;32m     14\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([indices[:start], indices[end:]])\n\u001b[1;32m---> 16\u001b[0m X_train_cv, y_train_cv \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m]\u001b[49m, y[train_indices]\n\u001b[0;32m     17\u001b[0m X_val_cv, y_val_cv \u001b[38;5;241m=\u001b[39m X[val_indices], y[val_indices]\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_cv, y_train_cv)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([22360, 14755,  4851, 29398, 27381, 23040,  1611, 29109, 30680, 17118,\\n       ...\\n        7823,   657, 12932,  5455, 22938,  9876, 25378, 12481, 25907, 16966],\\n      dtype='int32', length=26247)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import itertools\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes for Ridge\n",
    "ridge_best_score = -np.inf\n",
    "ridge_best_mse = np.inf\n",
    "ridge_best_params = {}\n",
    "ridge_results = []\n",
    "\n",
    "# Quá trình tuning tham số Ridge Regression\n",
    "for fit_intercept in param_grids['Ridge']['fit_intercept']:\n",
    "    for normalize in [True, False]:  # Giờ sử dụng chuẩn hóa với StandardScaler\n",
    "        # Sử dụng pipeline với StandardScaler và Ridge\n",
    "        if normalize:\n",
    "            ridge_model = make_pipeline(StandardScaler(), Ridge(fit_intercept=fit_intercept))\n",
    "        else:\n",
    "            ridge_model = Ridge(fit_intercept=fit_intercept)\n",
    "        \n",
    "        # Đánh giá mô hình với k-fold cross-validation\n",
    "        scores = cross_validate_regression(ridge_model, X_train, y_train, k=5)\n",
    "        \n",
    "        avg_r2 = scores['r2']\n",
    "        avg_mse = scores['mse']\n",
    "        \n",
    "        # Lưu kết quả vào danh sách\n",
    "        ridge_results.append({\n",
    "            'fit_intercept': fit_intercept,\n",
    "            'normalize': normalize,\n",
    "            'R2': avg_r2,\n",
    "            'MSE': avg_mse\n",
    "        })\n",
    "        \n",
    "        # Cập nhật tham số tốt nhất\n",
    "        if avg_r2 > ridge_best_score and avg_mse < ridge_best_mse:\n",
    "            ridge_best_score = avg_r2\n",
    "            ridge_best_mse = avg_mse\n",
    "            ridge_best_params = {\n",
    "                'fit_intercept': fit_intercept,\n",
    "                'normalize': normalize\n",
    "            }\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll Ridge parameter tuning results:\")\n",
    "for result in ridge_results:\n",
    "    print(f\"fit_intercept = {result['fit_intercept']}, normalize = {result['normalize']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning Ridge Completed!\")\n",
    "print(f\"Best parameter: {ridge_best_params}\")\n",
    "print(f\"Best R^2: {ridge_best_score}\")\n",
    "print(f\"Best MSE: {ridge_best_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "if ridge_best_params['normalize']:\n",
    "    ridge_best_model = make_pipeline(StandardScaler(), Ridge(fit_intercept=ridge_best_params['fit_intercept']))\n",
    "else:\n",
    "    ridge_best_model = Ridge(fit_intercept=ridge_best_params['fit_intercept'])\n",
    "\n",
    "ridge_best_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "ridge_y_pred_test = ridge_best_model.predict(X_test)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_y_pred_test)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_y_pred_test)\n",
    "ridge_test_rmse = np.sqrt(ridge_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nRidge Test Results:\")\n",
    "print(f\"R^2: {ridge_test_r2}\")\n",
    "print(f\"MSE: {ridge_test_mse}\")\n",
    "print(f\"RMSE: {ridge_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes\n",
    "lasso_best_score = -np.inf\n",
    "lasso_best_mse = np.inf\n",
    "lasso_best_params = {}\n",
    "lasso_results = []\n",
    "\n",
    "# Fine-tuning Lasso Regression\n",
    "for alpha in param_grids['Lasso']['alpha']:\n",
    "    # Sử dụng pipeline với StandardScaler và Lasso\n",
    "    model = make_pipeline(StandardScaler(), Lasso(alpha=alpha, random_state=18))\n",
    "    \n",
    "    # Đánh giá mô hình với k-fold cross-validation\n",
    "    scores = cross_validate_regression(model, X_train, y_train, k=5)\n",
    "    \n",
    "    avg_r2 = scores['r2']\n",
    "    avg_mse = scores['mse']\n",
    "    \n",
    "    # Lưu kết quả vào danh sách\n",
    "    lasso_results.append({\n",
    "        'alpha': alpha,\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    })\n",
    "    \n",
    "    # Cập nhật tham số tốt nhất\n",
    "    if avg_r2 > lasso_best_score and avg_mse < lasso_best_mse:\n",
    "        lasso_best_score = avg_r2\n",
    "        lasso_best_mse = avg_mse\n",
    "        lasso_best_params = {'alpha': alpha}\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll Lasso parameter tuning results:\")\n",
    "for result in lasso_results:\n",
    "    print(f\"alpha = {result['alpha']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning Lasso Completed!\")\n",
    "print(f\"Best parameter: {lasso_best_params}\")\n",
    "print(f\"Best R^2: {lasso_best_score}\")\n",
    "print(f\"Best MSE: {lasso_best_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "best_lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=lasso_best_params['alpha'], random_state=18))\n",
    "best_lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "lasso_y_pred_test = best_lasso_model.predict(X_test)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_y_pred_test)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_y_pred_test)\n",
    "lasso_test_rmse = np.sqrt(lasso_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nLasso Test Results:\")\n",
    "print(f\"R^2: {lasso_test_r2}\")\n",
    "print(f\"MSE: {lasso_test_mse}\")\n",
    "print(f\"RMSE: {lasso_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes\n",
    "best_svr_score = -np.inf\n",
    "best_svr_mse = np.inf\n",
    "best_svr_params = {}\n",
    "svr_results = []\n",
    "\n",
    "# Fine-tuning SVR with max_iter included\n",
    "for C, kernel, epsilon, max_iter in itertools.product(\n",
    "    param_grids['SVR']['C'],\n",
    "    param_grids['SVR']['kernel'],\n",
    "    param_grids['SVR']['epsilon'],\n",
    "    param_grids['SVR']['max_iter']  \n",
    "):\n",
    "    # Sử dụng pipeline với StandardScaler và SVR\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVR(C=C, kernel=kernel, epsilon=epsilon, max_iter=max_iter)\n",
    "    )\n",
    "    # Đánh giá mô hình với k-fold cross-validation\n",
    "    scores = cross_validate_regression(model, X_train, y_train, k=5)\n",
    "    \n",
    "    avg_r2 = scores['r2']\n",
    "    avg_mse = scores['mse']\n",
    "    \n",
    "    # Lưu kết quả vào danh sách\n",
    "    svr_results.append({\n",
    "        'C': C,\n",
    "        'kernel': kernel,\n",
    "        'epsilon': epsilon,\n",
    "        'max_iter': max_iter,\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    })\n",
    "    \n",
    "    # Cập nhật tham số tốt nhất\n",
    "    if avg_r2 > best_svr_score and avg_mse < best_svr_mse:\n",
    "        best_svr_score = avg_r2\n",
    "        best_svr_mse = avg_mse\n",
    "        best_svr_params = {\n",
    "            'C': C,\n",
    "            'kernel': kernel,\n",
    "            'epsilon': epsilon,\n",
    "            'max_iter': max_iter\n",
    "        }\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll SVR parameter tuning results:\")\n",
    "for result in svr_results:\n",
    "    print(f\"C = {result['C']}, kernel = {result['kernel']}, epsilon = {result['epsilon']}, max_iter = {result['max_iter']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning SVR Completed!\")\n",
    "print(f\"Best parameter: {best_svr_params}\")\n",
    "print(f\"Best R^2: {best_svr_score}\")\n",
    "print(f\"Best MSE: {best_svr_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "best_svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(\n",
    "        C=best_svr_params['C'],\n",
    "        kernel=best_svr_params['kernel'],\n",
    "        epsilon=best_svr_params['epsilon'],\n",
    "        max_iter=best_svr_params['max_iter']\n",
    "    )\n",
    ")\n",
    "\n",
    "best_svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "svr_y_pred_test = best_svr_model.predict(X_test)\n",
    "svr_test_r2 = r2_score(y_test, svr_y_pred_test)\n",
    "svr_test_mse = mean_squared_error(y_test, svr_y_pred_test)\n",
    "svr_test_rmse = np.sqrt(svr_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nSVR Test Results:\")\n",
    "print(f\"R^2: {svr_test_r2}\")\n",
    "print(f\"MSE: {svr_test_mse}\")\n",
    "print(f\"RMSE: {svr_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Lưu các kết quả của 3 mô hình vào một dictionary\n",
    "results = {\n",
    "    'Model': ['Ridge', 'Lasso', 'SVR'],\n",
    "    'R²': [ridge_test_r2, lasso_test_r2, svr_test_r2],\n",
    "    'MSE': [ridge_test_mse, lasso_test_mse, svr_test_mse],\n",
    "    'RMSE': [ridge_test_rmse, lasso_test_rmse, svr_test_rmse]\n",
    "}\n",
    "\n",
    "# Chọn mô hình tốt nhất (Dựa trên MSE hoặc R² cao nhất)\n",
    "best_model_index = np.argmin(results['MSE'])  # Chọn mô hình có MSE thấp nhất\n",
    "best_model_name = results['Model'][best_model_index]\n",
    "best_model_r2 = results['R²'][best_model_index]\n",
    "best_model_mse = results['MSE'][best_model_index]\n",
    "best_model_rmse = results['RMSE'][best_model_index]\n",
    "\n",
    "# In kết quả mô hình tốt nhất\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best Model R²: {best_model_r2}\")\n",
    "print(f\"Best Model MSE: {best_model_mse}\")\n",
    "print(f\"Best Model RMSE: {best_model_rmse}\")\n",
    "\n",
    "# Vẽ biểu đồ so sánh MSE, RMSE và R² của các mô hình\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Biểu đồ MSE\n",
    "sns.barplot(x=results['Model'], y=results['MSE'], ax=ax[0])\n",
    "ax[0].set_title('Mean Squared Error (MSE)')\n",
    "ax[0].set_xlabel('Model')\n",
    "ax[0].set_ylabel('MSE')\n",
    "\n",
    "# Biểu đồ RMSE\n",
    "sns.barplot(x=results['Model'], y=results['RMSE'], ax=ax[1])\n",
    "ax[1].set_title('Root Mean Squared Error (RMSE)')\n",
    "ax[1].set_xlabel('Model')\n",
    "ax[1].set_ylabel('RMSE')\n",
    "\n",
    "# Biểu đồ R²\n",
    "sns.barplot(x=results['Model'], y=results['R²'], ax=ax[2])\n",
    "ax[2].set_title('R² Score')\n",
    "ax[2].set_xlabel('Model')\n",
    "ax[2].set_ylabel('R²')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In bảng kết quả để so sánh\n",
    "print(\"\\nComparison of Models:\")\n",
    "for model, mse, rmse, r2 in zip(results['Model'], results['MSE'], results['RMSE'], results['R²']):\n",
    "    print(f\"{model} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In công thức của mô hình tốt nhất\n",
    "if best_model_name == 'Ridge':\n",
    "    coefficients = ridge_best_model.coef_\n",
    "    intercept = ridge_best_model.intercept_\n",
    "    formula = f\"y = {intercept:.4f}\"\n",
    "    for i, coef in enumerate(coefficients):\n",
    "        formula += f\" + ({coef:.4f}) * {X_train.columns[i]}\"\n",
    "    print(f\"Formula of model Ridge: {formula}\")\n",
    "\n",
    "elif best_model_name == 'Lasso':\n",
    "    coefficients = best_lasso_model.coef_\n",
    "    intercept = best_lasso_model.intercept_\n",
    "    formula = f\"y = {intercept:.4f}\"\n",
    "    for i, coef in enumerate(coefficients):\n",
    "        formula += f\" + ({coef:.4f}) * {X_train.columns[i]}\"\n",
    "    print(f\"Formula of model Lasso: {formula}\")\n",
    "\n",
    "elif best_model_name == 'SVR':\n",
    "    print(f\"Information of model SVR:\")\n",
    "    print(f\"C (Regularization parameter): {best_svr_model.C}\")\n",
    "    print(f\"epsilon (Margin of tolerance): {best_svr_model.epsilon}\")\n",
    "    print(f\"Number of support vectors: {len(best_svr_model.support_)}\")\n",
    "    print(f\"Support vectors: {best_svr_model.support_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
