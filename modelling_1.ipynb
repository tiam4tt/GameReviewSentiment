{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 32808 samples\n",
      "Test set size: 8202 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Create 'is_paid' feature: 0 for free, 1 for paid\n",
    "data['is_paid'] = data['Pricing'].apply(lambda x: 0 if x == 0.0 else 1)\n",
    "\n",
    "# Extract 'Month' from 'Release Date'\n",
    "data['Release Date'] = pd.to_datetime(data['Release Date'], errors='coerce')\n",
    "data['Release Month'] = data['Release Date'].dt.month\n",
    "\n",
    "# Filter to only paid games (is_paid == 1)\n",
    "data_paid = data[data['is_paid'] == 1].reset_index(drop=True)\n",
    "\n",
    "# Select features and target\n",
    "features = ['Game Genre', 'Developer', 'Release Month', 'Pricing']\n",
    "target = 'Rating'\n",
    "\n",
    "X = data_paid[features]\n",
    "y = data_paid[target]\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Game Genre', 'Developer']\n",
    "numerical_features = ['Release Month', 'Pricing']\n",
    "\n",
    "# Preprocessing pipelines for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing to the features\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert the preprocessed features to a DataFrame\n",
    "encoded_cat_features = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "encoded_num_features = numerical_features\n",
    "all_features = list(encoded_cat_features) + encoded_num_features\n",
    "\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed.toarray(), columns=all_features)\n",
    "\n",
    "# Reset the index of X_preprocessed_df to align with y\n",
    "X_preprocessed_df = X_preprocessed_df.reset_index(drop=True)\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed_df, y, test_size=0.2, random_state=18\n",
    ")\n",
    "\n",
    "# Display the sizes of the splits\n",
    "print(f'Training set size: {X_train.shape[0]} samples')\n",
    "print(f'Test set size: {X_test.shape[0]} samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Parameter Grids for Regression Models\n",
    "import itertools\n",
    "# Parameter grids for each model\n",
    "param_grids = {\n",
    "    'Ridge': {\n",
    "        'fit_intercept': [True, False],\n",
    "        'normalize': [True, False],\n",
    "        'alpha': [0.1, 1]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'xgboost':{\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1, 1],\n",
    "        'reg_lambda': [1, 10]\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': [ None, 'sqrt', 'log2']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Hàm cross-validation cho hồi quy\n",
    "def cross_validate_regression(model, X, y, k=5):\n",
    "    fold_size = len(X) // k\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    scores = {'mse': [], 'rmse': [], 'r2': []}\n",
    "    \n",
    "    for fold in range(k):\n",
    "        start = fold * fold_size\n",
    "        end = start + fold_size if fold != k-1 else len(X)\n",
    "        val_indices = indices[start:end]\n",
    "        train_indices = np.concatenate([indices[:start], indices[end:]])\n",
    "        \n",
    "        # Convert X và y thành numpy arrays nếu là pandas DataFrame hoặc Series\n",
    "        if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.DataFrame, pd.Series)):\n",
    "            y = y.values\n",
    "        \n",
    "        X_train_cv, y_train_cv = X[train_indices], y[train_indices]\n",
    "        X_val_cv, y_val_cv = X[val_indices], y[val_indices]\n",
    "        \n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = model.predict(X_val_cv)\n",
    "        \n",
    "        mse = mean_squared_error(y_val_cv, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_val_cv, y_pred)\n",
    "        \n",
    "        scores['mse'].append(mse)\n",
    "        scores['rmse'].append(rmse)\n",
    "        scores['r2'].append(r2)\n",
    "        \n",
    "    avg_scores = {metric: np.mean(values) for metric, values in scores.items()}\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([22360, 14755,  4851, 29398, 27381, 23040,  1611, 29109, 30680, 17118,\\n       ...\\n        7823,   657, 12932,  5455, 22938,  9876, 25378, 12481, 25907, 16966],\\n      dtype='int32', length=26247)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fit_intercept \u001b[38;5;129;01min\u001b[39;00m param_grids[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinearRegression\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_intercept\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     12\u001b[0m     model \u001b[38;5;241m=\u001b[39m LinearRegression(\n\u001b[0;32m     13\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39mfit_intercept\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# 'normalize' parameter removed\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     )\n\u001b[1;32m---> 16\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     avg_r2 \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m     lr_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_intercept\u001b[39m\u001b[38;5;124m'\u001b[39m: fit_intercept,\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_r2\n\u001b[0;32m     21\u001b[0m     })\n",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m, in \u001b[0;36mcross_validate_regression\u001b[1;34m(model, X, y, k)\u001b[0m\n\u001b[0;32m     13\u001b[0m val_indices \u001b[38;5;241m=\u001b[39m indices[start:end]\n\u001b[0;32m     14\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([indices[:start], indices[end:]])\n\u001b[1;32m---> 16\u001b[0m X_train_cv, y_train_cv \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m]\u001b[49m, y[train_indices]\n\u001b[0;32m     17\u001b[0m X_val_cv, y_val_cv \u001b[38;5;241m=\u001b[39m X[val_indices], y[val_indices]\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_cv, y_train_cv)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([22360, 14755,  4851, 29398, 27381, 23040,  1611, 29109, 30680, 17118,\\n       ...\\n        7823,   657, 12932,  5455, 22938,  9876, 25378, 12481, 25907, 16966],\\n      dtype='int32', length=26247)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import itertools\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes for Ridge\n",
    "ridge_best_score = -np.inf\n",
    "ridge_best_mse = np.inf\n",
    "ridge_best_params = {}\n",
    "ridge_results = []\n",
    "\n",
    "# Quá trình tuning tham số Ridge Regression\n",
    "for fit_intercept in param_grids['Ridge']['fit_intercept']:\n",
    "    for normalize in [True, False]:  # Giờ sử dụng chuẩn hóa với StandardScaler\n",
    "        # Sử dụng pipeline với StandardScaler và Ridge\n",
    "        if normalize:\n",
    "            ridge_model = make_pipeline(StandardScaler(), Ridge(fit_intercept=fit_intercept))\n",
    "        else:\n",
    "            ridge_model = Ridge(fit_intercept=fit_intercept)\n",
    "        \n",
    "        # Đánh giá mô hình với k-fold cross-validation\n",
    "        scores = cross_validate_regression(ridge_model, X_train, y_train, k=5)\n",
    "        \n",
    "        avg_r2 = scores['r2']\n",
    "        avg_mse = scores['mse']\n",
    "        \n",
    "        # Lưu kết quả vào danh sách\n",
    "        ridge_results.append({\n",
    "            'fit_intercept': fit_intercept,\n",
    "            'normalize': normalize,\n",
    "            'R2': avg_r2,\n",
    "            'MSE': avg_mse\n",
    "        })\n",
    "        \n",
    "        # Cập nhật tham số tốt nhất\n",
    "        if avg_r2 > ridge_best_score and avg_mse < ridge_best_mse:\n",
    "            ridge_best_score = avg_r2\n",
    "            ridge_best_mse = avg_mse\n",
    "            ridge_best_params = {\n",
    "                'fit_intercept': fit_intercept,\n",
    "                'normalize': normalize\n",
    "            }\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll Ridge parameter tuning results:\")\n",
    "for result in ridge_results:\n",
    "    print(f\"fit_intercept = {result['fit_intercept']}, normalize = {result['normalize']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning Ridge Completed!\")\n",
    "print(f\"Best parameter: {ridge_best_params}\")\n",
    "print(f\"Best R^2: {ridge_best_score}\")\n",
    "print(f\"Best MSE: {ridge_best_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "if ridge_best_params['normalize']:\n",
    "    ridge_best_model = make_pipeline(StandardScaler(), Ridge(fit_intercept=ridge_best_params['fit_intercept']))\n",
    "else:\n",
    "    ridge_best_model = Ridge(fit_intercept=ridge_best_params['fit_intercept'])\n",
    "\n",
    "ridge_best_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "ridge_y_pred_test = ridge_best_model.predict(X_test)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_y_pred_test)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_y_pred_test)\n",
    "ridge_test_rmse = np.sqrt(ridge_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nRidge Test Results:\")\n",
    "print(f\"R^2: {ridge_test_r2}\")\n",
    "print(f\"MSE: {ridge_test_mse}\")\n",
    "print(f\"RMSE: {ridge_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes\n",
    "lasso_best_score = -np.inf\n",
    "lasso_best_mse = np.inf\n",
    "lasso_best_params = {}\n",
    "lasso_results = []\n",
    "\n",
    "# Fine-tuning Lasso Regression\n",
    "for alpha in param_grids['Lasso']['alpha']:\n",
    "    # Sử dụng pipeline với StandardScaler và Lasso\n",
    "    model = make_pipeline(StandardScaler(), Lasso(alpha=alpha, random_state=18))\n",
    "    \n",
    "    # Đánh giá mô hình với k-fold cross-validation\n",
    "    scores = cross_validate_regression(model, X_train, y_train, k=5)\n",
    "    \n",
    "    avg_r2 = scores['r2']\n",
    "    avg_mse = scores['mse']\n",
    "    \n",
    "    # Lưu kết quả vào danh sách\n",
    "    lasso_results.append({\n",
    "        'alpha': alpha,\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    })\n",
    "    \n",
    "    # Cập nhật tham số tốt nhất\n",
    "    if avg_r2 > lasso_best_score and avg_mse < lasso_best_mse:\n",
    "        lasso_best_score = avg_r2\n",
    "        lasso_best_mse = avg_mse\n",
    "        lasso_best_params = {'alpha': alpha}\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll Lasso parameter tuning results:\")\n",
    "for result in lasso_results:\n",
    "    print(f\"alpha = {result['alpha']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning Lasso Completed!\")\n",
    "print(f\"Best parameter: {lasso_best_params}\")\n",
    "print(f\"Best R^2: {lasso_best_score}\")\n",
    "print(f\"Best MSE: {lasso_best_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "best_lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=lasso_best_params['alpha'], random_state=18))\n",
    "best_lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "lasso_y_pred_test = best_lasso_model.predict(X_test)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_y_pred_test)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_y_pred_test)\n",
    "lasso_test_rmse = np.sqrt(lasso_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nLasso Test Results:\")\n",
    "print(f\"R^2: {lasso_test_r2}\")\n",
    "print(f\"MSE: {lasso_test_mse}\")\n",
    "print(f\"RMSE: {lasso_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes\n",
    "xgb_best_score = -np.inf\n",
    "xgb_best_mse = np.inf\n",
    "xgb_best_params = {}\n",
    "xgb_results = []\n",
    "\n",
    "# Fine-tuning XGBoost with parameter grid\n",
    "for n_estimators, learning_rate, max_depth, subsample, colsample_bytree, reg_alpha, reg_lambda in itertools.product(\n",
    "    param_grids['xgboost']['n_estimators'],\n",
    "    param_grids['xgboost']['learning_rate'],\n",
    "    param_grids['xgboost']['max_depth'],\n",
    "    param_grids['xgboost']['subsample'],\n",
    "    param_grids['xgboost']['colsample_bytree'],\n",
    "    param_grids['xgboost']['reg_alpha'],\n",
    "    param_grids['xgboost']['reg_lambda']\n",
    "):\n",
    "    # Create XGBoost Regressor model with the parameters\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),  # Normalize data\n",
    "        XGBRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            reg_alpha=reg_alpha,\n",
    "            reg_lambda=reg_lambda,\n",
    "            objective='reg:squarederror',\n",
    "            verbosity=0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Cross-validate the model\n",
    "    scores = cross_validate_regression(model, X_train, y_train, k=5)\n",
    "    avg_r2 = scores['r2']\n",
    "    avg_mse = scores['mse']\n",
    "    \n",
    "    # Append results to the list\n",
    "    xgb_results.append({\n",
    "        'n_estimators': n_estimators,\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth': max_depth,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'reg_alpha': reg_alpha,\n",
    "        'reg_lambda': reg_lambda,\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    })\n",
    "    \n",
    "    # Update the best model parameters if current R² is higher\n",
    "    if avg_r2 > xgb_best_score and avg_mse < xgb_best_mse:\n",
    "        xgb_best_score = avg_r2\n",
    "        xgb_best_mse = avg_mse\n",
    "        xgb_best_params = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'learning_rate': learning_rate,\n",
    "            'max_depth': max_depth,\n",
    "            'subsample': subsample,\n",
    "            'colsample_bytree': colsample_bytree,\n",
    "            'reg_alpha': reg_alpha,\n",
    "            'reg_lambda': reg_lambda\n",
    "        }\n",
    "\n",
    "# Print all tuning results\n",
    "print(\"\\nAll XGBoost parameter tuning results:\")\n",
    "for result in xgb_results:\n",
    "    print(f\"n_estimators = {result['n_estimators']}, learning_rate = {result['learning_rate']}, \"\n",
    "          f\"max_depth = {result['max_depth']}, subsample = {result['subsample']}, \"\n",
    "          f\"colsample_bytree = {result['colsample_bytree']}, reg_alpha = {result['reg_alpha']}, \"\n",
    "          f\"reg_lambda = {result['reg_lambda']}, R² = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# Fine-tuning report\n",
    "print(\"\\nFine-Tuning XGBoost Completed!\")\n",
    "print(f\"Best Parameters: {xgb_best_params}\")\n",
    "print(f\"Best R²: {xgb_best_score}\")\n",
    "print(f\"Best MSE: {xgb_best_mse}\")\n",
    "\n",
    "# Train the best XGBoost model on the full training data\n",
    "best_xgb_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    XGBRegressor(\n",
    "        n_estimators=xgb_best_params['n_estimators'],\n",
    "        learning_rate=xgb_best_params['learning_rate'],\n",
    "        max_depth=xgb_best_params['max_depth'],\n",
    "        subsample=xgb_best_params['subsample'],\n",
    "        colsample_bytree=xgb_best_params['colsample_bytree'],\n",
    "        reg_alpha=xgb_best_params['reg_alpha'],\n",
    "        reg_lambda=xgb_best_params['reg_lambda'],\n",
    "        objective='reg:squarederror',\n",
    "        verbosity=0\n",
    "    )\n",
    ")\n",
    "\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and calculate R², MSE\n",
    "xgb_y_pred_test = best_xgb_model.predict(X_test)\n",
    "xgb_test_r2 = r2_score(y_test, xgb_y_pred_test)\n",
    "xgb_test_mse = mean_squared_error(y_test, xgb_y_pred_test)\n",
    "xgb_test_rmse = np.sqrt(xgb_test_mse)\n",
    "\n",
    "# Print test results\n",
    "print(\"\\nXGBoost Test Results:\")\n",
    "print(f\"R²: {xgb_test_r2}\")\n",
    "print(f\"MSE: {xgb_test_mse}\")\n",
    "print(f\"RMSE: {xgb_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import itertools\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes\n",
    "dt_best_score = -np.inf\n",
    "dt_best_mse = np.inf\n",
    "dt_best_params = {}\n",
    "dt_results = []\n",
    "\n",
    "# Fine-tuning Decision Tree with parameter grid\n",
    "for max_depth, min_samples_split, min_samples_leaf, max_features in itertools.product(\n",
    "    param_grids['decision_tree']['max_depth'],\n",
    "    param_grids['decision_tree']['min_samples_split'],\n",
    "    param_grids['decision_tree']['min_samples_leaf'],\n",
    "    param_grids['decision_tree']['max_features']\n",
    "):\n",
    "    # Create Decision Tree Regressor model\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),  # Normalize data\n",
    "        DecisionTreeRegressor(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            random_state=18\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Cross-validate the model\n",
    "    scores = cross_validate_regression(model, X_train, y_train, k=5)\n",
    "    avg_r2 = scores['r2']\n",
    "    avg_mse = scores['mse']\n",
    "\n",
    "    # Append results to the list\n",
    "    dt_results.append({\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'max_features': max_features,\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    })\n",
    "\n",
    "    # Update the best model parameters if current R² is higher\n",
    "    if avg_r2 > dt_best_score and avg_mse < dt_best_mse:\n",
    "        dt_best_score = avg_r2\n",
    "        dt_best_mse = avg_mse\n",
    "        dt_best_params = {\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            'max_features': max_features\n",
    "        }\n",
    "\n",
    "# Print all tuning results\n",
    "print(\"\\nAll Decision Tree parameter tuning results:\")\n",
    "for result in dt_results:\n",
    "    print(f\"max_depth = {result['max_depth']}, min_samples_split = {result['min_samples_split']}, \"\n",
    "          f\"min_samples_leaf = {result['min_samples_leaf']}, max_features = {result['max_features']}, \"\n",
    "          f\"R² = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# Fine-tuning report\n",
    "print(\"\\nFine-Tuning Decision Tree Completed!\")\n",
    "print(f\"Best Parameters: {dt_best_params}\")\n",
    "print(f\"Best R²: {dt_best_score}\")\n",
    "print(f\"Best MSE: {dt_best_mse}\")\n",
    "\n",
    "# Train the best Decision Tree model on the full training data\n",
    "best_dt_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    DecisionTreeRegressor(\n",
    "        max_depth=dt_best_params['max_depth'],\n",
    "        min_samples_split=dt_best_params['min_samples_split'],\n",
    "        min_samples_leaf=dt_best_params['min_samples_leaf'],\n",
    "        max_features=dt_best_params['max_features'],\n",
    "        random_state=18\n",
    "    )\n",
    ")\n",
    "\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and calculate R², MSE\n",
    "dt_y_pred_test = best_dt_model.predict(X_test)\n",
    "dt_test_r2 = r2_score(y_test, dt_y_pred_test)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_y_pred_test)\n",
    "dt_test_rmse = np.sqrt(dt_test_mse)\n",
    "\n",
    "# Print test results\n",
    "print(\"\\nDecision Tree Test Results:\")\n",
    "print(f\"R²: {dt_test_r2}\")\n",
    "print(f\"MSE: {dt_test_mse}\")\n",
    "print(f\"RMSE: {dt_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Lưu các kết quả của 3 mô hình vào một dictionary\n",
    "results = {\n",
    "    'Model': ['Ridge', 'Lasso', 'xgboost', 'decision_tree'],\n",
    "    'R²': [ridge_test_r2, lasso_test_r2, xgb_test_r2, dt_test_r2],\n",
    "    'MSE': [ridge_test_mse, lasso_test_mse, xgb_test_mse, dt_test_mse],\n",
    "    'RMSE': [ridge_test_rmse, lasso_test_rmse, xgb_test_rmse, dt_test_rmse]\n",
    "}\n",
    "\n",
    "# Chọn mô hình tốt nhất (Dựa trên MSE hoặc R² cao nhất)\n",
    "best_model_index = np.argmin(results['MSE'])  # Chọn mô hình có MSE thấp nhất\n",
    "best_model_name = results['Model'][best_model_index]\n",
    "best_model_r2 = results['R²'][best_model_index]\n",
    "best_model_mse = results['MSE'][best_model_index]\n",
    "best_model_rmse = results['RMSE'][best_model_index]\n",
    "\n",
    "# In kết quả mô hình tốt nhất\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best Model R²: {best_model_r2}\")\n",
    "print(f\"Best Model MSE: {best_model_mse}\")\n",
    "print(f\"Best Model RMSE: {best_model_rmse}\")\n",
    "\n",
    "# Vẽ biểu đồ so sánh MSE, RMSE và R² của các mô hình\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Màu sắc để làm nổi bật mô hình tốt nhất\n",
    "colors = ['lightblue' if i != best_model_index else 'lightgreen' for i in range(len(results['Model']))]\n",
    "\n",
    "# Biểu đồ MSE\n",
    "sns.barplot(x=results['Model'], y=results['MSE'], ax=ax[0], palette=colors)\n",
    "ax[0].set_title('Mean Squared Error (MSE)', fontsize=14)\n",
    "ax[0].set_xlabel('Model', fontsize=12)\n",
    "ax[0].set_ylabel('MSE', fontsize=12)\n",
    "ax[0].bar_label(ax[0].containers[0], fmt='%.2f', fontsize=10)\n",
    "\n",
    "# Biểu đồ RMSE\n",
    "sns.barplot(x=results['Model'], y=results['RMSE'], ax=ax[1], palette=colors)\n",
    "ax[1].set_title('Root Mean Squared Error (RMSE)', fontsize=14)\n",
    "ax[1].set_xlabel('Model', fontsize=12)\n",
    "ax[1].set_ylabel('RMSE', fontsize=12)\n",
    "ax[1].bar_label(ax[1].containers[0], fmt='%.2f', fontsize=10)\n",
    "\n",
    "# Biểu đồ R²\n",
    "sns.barplot(x=results['Model'], y=results['R²'], ax=ax[2], palette=colors)\n",
    "ax[2].set_title('R² Score', fontsize=14)\n",
    "ax[2].set_xlabel('Model', fontsize=12)\n",
    "ax[2].set_ylabel('R²', fontsize=12)\n",
    "ax[2].bar_label(ax[2].containers[0], fmt='%.2f', fontsize=10)\n",
    "\n",
    "# Làm nổi bật mô hình tốt nhất\n",
    "for a in ax:\n",
    "    a.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "    a.tick_params(axis='x', labelrotation=15)\n",
    "\n",
    "plt.suptitle('Comparison of Model Performance', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# In bảng kết quả để so sánh\n",
    "print(\"\\nComparison of Models:\")\n",
    "for model, mse, rmse, r2 in zip(results['Model'], results['MSE'], results['RMSE'], results['R²']):\n",
    "    print(f\"{model} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
