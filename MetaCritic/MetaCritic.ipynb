{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': \"Mozilla/5.0 (platform; rv:gecko-version) Gecko/gecko-trail Firefox/132.0.1-1\"\n",
    "}\n",
    "\n",
    "def get_sitemaps() -> list:\n",
    "    # URL\n",
    "    sitemap = \"https://www.metacritic.com/games.xml\"\n",
    "    sm_response = requests.get(sitemap, headers=headers)\n",
    "    sm_soup = BeautifulSoup(sm_response.text, 'xml')\n",
    "    # time.sleep(1)\n",
    "    return [sm.get_text(strip=True) for sm in sm_soup.find_all('sitemap')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(sitemap: str):\n",
    "    try:\n",
    "        urls_response = requests.get(sitemap, headers=headers, timeout=3)\n",
    "    except Exception:\n",
    "        return sitemap\n",
    "    \n",
    "    urls_soup = BeautifulSoup(urls_response.text, 'xml')\n",
    "    # time.sleep(1)\n",
    "    urls = urls_soup.find_all('loc')\n",
    "    if not urls:\n",
    "        raise ValueError('No URLs found in sitemap')\n",
    "    \n",
    "    return [url.get_text(strip=True) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url):\n",
    "    data = {\n",
    "        'Game Title': [],\n",
    "        'Game Genre': [],\n",
    "        'Pricing': 'n/a',\n",
    "        'Developer': [],\n",
    "        'Release Date': [],\n",
    "        'Platform': [],\n",
    "        'Rating': [],\n",
    "        'Number of Ratings': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "    except Exception:\n",
    "        raise Exception(e)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    \n",
    "    info = soup.find('div', class_='c-productHero_score-container u-flexbox u-flexbox-column g-bg-white')\n",
    "    \n",
    "    # rating\n",
    "    ratings = info.find_all('div', class_='c-productScoreInfo_scoreContent')\n",
    "    \n",
    "    score = ratings[1].find('div', class_='c-productScoreInfo_scoreNumber').get_text(strip=True)\n",
    "    \n",
    "    if score == 'tbd':\n",
    "        raise ValueError('tbd')\n",
    "\n",
    "    data['Rating'] = score\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    num_rating_text = ratings[1].find('span', class_='c-productScoreInfo_reviewsTotal').get_text(strip=True)\n",
    "    num_ratings = re.search(r'(\\d[\\d,]*)', num_rating_text).group(1)\n",
    "    \n",
    "    data['Number of Ratings'] = num_ratings.replace(',', '')\n",
    "    \n",
    "    # title\n",
    "    data['Game Title'] = soup.find('div', class_='c-productHero_title').get_text(strip=True)\n",
    "    \n",
    "    # genre\n",
    "    genres = soup.find('ul', class_='c-genreList').select('li')\n",
    "    data['Game Genre'] = \", \".join([genre.get_text(strip=True) for genre in genres])\n",
    "    \n",
    "    \n",
    "    # developer\n",
    "    devs = soup.find('div', class_='c-gameDetails_Developer').select('.c-gameDetails_listItem')\n",
    "    data['Developer'] = \", \".join([dev.get_text(strip=True) for dev in devs])\n",
    "    \n",
    "    # release date\n",
    "    release_date = soup.find('div', class_='c-gameDetails_ReleaseDate').select(\"span\")[1].get_text(strip=True)\n",
    "    data['Release Date'] = release_date\n",
    "    \n",
    "    # platforms\n",
    "    platforms = [li.get_text(strip=True) for li in soup.select(\".c-gameDetails_Platforms ul li\")]\n",
    "    data['Platform'] = \", \".join(platforms)\n",
    "    \n",
    "    return pd.DataFrame([data])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_sitemap = get_sitemaps()\n",
    "total_sitemaps = len(main_sitemap)\n",
    "\n",
    "def get_game_links(sitemaps, retry=0):\n",
    "    \n",
    "    if len(sitemaps) == 0:\n",
    "        return\n",
    "\n",
    "    missed_urls = []\n",
    "    success_urls = []\n",
    "\n",
    "    for i,sitemap in enumerate(sitemaps):\n",
    "        \n",
    "        print(f\"\\rFound {len(success_urls)}; searching at {i}/{len(sitemaps)}\", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            urls = get_urls(sitemap)\n",
    "            success_urls += urls\n",
    "        except Exception:\n",
    "            missed_urls.append(sitemap)\n",
    "            continue\n",
    "\n",
    "    if success_urls:\n",
    "        with open(f\"{retry}_metacritic.txt\", \"w\") as file:\n",
    "            file.write(\"\\n\".join(success_urls))\n",
    "\n",
    "    print(f\"\\n{len(success_urls)} URLs found, {len(missed_urls)} sitemaps inaccessible\")\n",
    "    \n",
    "    get_game_links(missed_urls, retry + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_game_links(main_sitemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(urls: list, part: str):\n",
    "    size = len(urls)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "    df_list = []\n",
    "\n",
    "    for i,url in enumerate(urls):\n",
    "        try:\n",
    "            data = scrape_data(url)\n",
    "            df_list.append(data)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        print(f\"\\r[{int(((i+1)/size)*100)}%] {i}/{size}, scrapped {len(df_list)}\", end=\"\")\n",
    "            \n",
    "            \n",
    "    main_df = pd.concat(df_list, ignore_index=True)\n",
    "    main_df.to_csv(f\"{part}_metacritic_data.csv\", index=False)\n",
    "    \n",
    "    print(main_df.shape)\n",
    "    print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metacritic_urls.txt\", \"r\") as file:\n",
    "    urls = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chạy từng part\n",
    "> **NẾU CHIA THÀNH NHIỀU RANGE ĐỂ CHẠY THÌ ĐỪNG CHO HÀM `run()` VÀO VÒNG LẶP MÀ HÃY CHẠY RIÊNG MỖI CELL**\n",
    "### VD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] 4999/5000, scrapped 143(143, 8)\n",
      "                                          Game Title    Game Genre Pricing  \\\n",
      "0  Slayers X: Terminal Aftermath: Vengance of the...           FPS     n/a   \n",
      "1                                         Dungeons 4      Strategy     n/a   \n",
      "2                              Call of Duty: Warzone  Tactical FPS     n/a   \n",
      "3                                         Ravenbound    Action RPG     n/a   \n",
      "4                                OnlyFap Simulator 2        Action     n/a   \n",
      "\n",
      "            Developer  Release Date  \\\n",
      "0       Big Z Studios   Jun 1, 2023   \n",
      "1  Realmforge Studios   Nov 9, 2023   \n",
      "2       Infinity Ward  Nov 14, 2022   \n",
      "3   Systemic Reaction  Mar 30, 2023   \n",
      "4       BanzaiProject   Aug 6, 2022   \n",
      "\n",
      "                                            Platform Rating Number of Ratings  \n",
      "0  PC, PlayStation 4, Nintendo Switch, Xbox Serie...    7.0                 7  \n",
      "1  Xbox Series X, PlayStation 5, PC, Nintendo Switch    7.8                24  \n",
      "2  Xbox Series X, PlayStation 5, PC, PlayStation ...    3.9               317  \n",
      "3                                                 PC    4.3                 6  \n",
      "4                                                 PC    8.0                 8  \n"
     ]
    }
   ],
   "source": [
    "run(urls[230000:235000], \"part7.4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
