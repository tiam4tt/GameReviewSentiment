{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 16585 samples\n",
      "Validation set size: 2073 samples\n",
      "Test set size: 2074 samples\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Create 'is_paid' feature: 0 for free, 1 for paid\n",
    "data['is_paid'] = data['Pricing'].apply(lambda x: 0 if x == 0.0 else 1)\n",
    "\n",
    "# Extract 'Month' from 'Release Date'\n",
    "data['Release Date'] = pd.to_datetime(data['Release Date'], errors='coerce')\n",
    "data['Release Month'] = data['Release Date'].dt.month\n",
    "\n",
    "# Filter only free games (is_paid == 0)\n",
    "data_free = data[data['is_paid'] == 0]\n",
    "\n",
    "# Select features and target, excluding 'Pricing'\n",
    "features = ['Game Genre', 'Developer', 'Release Month']\n",
    "target = 'Rating'\n",
    "\n",
    "X = data_free[features]\n",
    "y = data_free[target]\n",
    "\n",
    "# Reset the index of y to align with X\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Game Genre', 'Developer']\n",
    "numerical_features = ['Release Month']\n",
    "\n",
    "# Preprocessing pipelines for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing to the features\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert the preprocessed features to a DataFrame\n",
    "encoded_cat_features = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "encoded_num_features = numerical_features\n",
    "all_features = list(encoded_cat_features) + encoded_num_features\n",
    "\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed.toarray(), columns=all_features)\n",
    "\n",
    "# Reset the index of X_preprocessed_df to align with y\n",
    "X_preprocessed_df = X_preprocessed_df.reset_index(drop=True)\n",
    "\n",
    "# Split data into training and temporary sets (80% train, 20% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_preprocessed_df, y, test_size=0.2, random_state=18\n",
    ")\n",
    "\n",
    "# Split temporary set into validation and test sets (50% each of temp -> 10% each of original)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=18\n",
    ")\n",
    "\n",
    "# Display the sizes of the splits\n",
    "print(f'Training set size: {X_train.shape[0]} samples')\n",
    "print(f'Validation set size: {X_valid.shape[0]} samples')\n",
    "print(f'Test set size: {X_test.shape[0]} samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Parameter Grids for Regression Models\n",
    "import itertools\n",
    "# Parameter grids for each model\n",
    "param_grids = {\n",
    "    'Ridge': {\n",
    "        'fit_intercept': [True, False],\n",
    "        'normalize': [True, False],\n",
    "        'alpha': [0.1, 1]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'epsilon': [0.1, 0.2],\n",
    "        'max_iter': [300, 500]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Hàm cross-validation cho hồi quy\n",
    "def cross_validate_regression(model, X, y, k=5):\n",
    "    fold_size = len(X) // k\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    scores = {'mse': [], 'rmse': [], 'r2': []}\n",
    "    \n",
    "    for fold in range(k):\n",
    "        start = fold * fold_size\n",
    "        end = start + fold_size if fold != k-1 else len(X)\n",
    "        val_indices = indices[start:end]\n",
    "        train_indices = np.concatenate([indices[:start], indices[end:]])\n",
    "        \n",
    "        # Convert X và y thành numpy arrays nếu là pandas DataFrame hoặc Series\n",
    "        if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "            X = X.values\n",
    "        if isinstance(y, (pd.DataFrame, pd.Series)):\n",
    "            y = y.values\n",
    "        \n",
    "        X_train_cv, y_train_cv = X[train_indices], y[train_indices]\n",
    "        X_val_cv, y_val_cv = X[val_indices], y[val_indices]\n",
    "        \n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = model.predict(X_val_cv)\n",
    "        \n",
    "        mse = mean_squared_error(y_val_cv, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_val_cv, y_pred)\n",
    "        \n",
    "        scores['mse'].append(mse)\n",
    "        scores['rmse'].append(rmse)\n",
    "        scores['r2'].append(r2)\n",
    "        \n",
    "    avg_scores = {metric: np.mean(values) for metric, values in scores.items()}\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tất cả các kết quả tuning tham số Ridge Regression:\n",
      "fit_intercept = True, normalize = True, R² = -0.040943208198915504, MSE = 279.9311825045913\n",
      "fit_intercept = True, normalize = False, R² = 0.1715295725415565, MSE = 222.7177978116731\n",
      "fit_intercept = False, normalize = True, R² = -19.44473509642173, MSE = 5481.023646644213\n",
      "fit_intercept = False, normalize = False, R² = -0.6372386033474914, MSE = 439.9111926524962\n",
      "\n",
      "Quá trình tuning tham số Ridge Regression đã hoàn thành!\n",
      "Tham số tốt nhất: {'fit_intercept': True, 'normalize': False}\n",
      "Điểm R² tốt nhất (CV): 0.1715295725415565\n",
      "MSE tốt nhất (CV): 222.7177978116731\n",
      "\n",
      "Kết quả trên tập kiểm tra với tham số tốt nhất:\n",
      "Điểm R² trên tập kiểm tra: 0.1812880254403204\n",
      "MSE trên tập kiểm tra: 224.76617575542244\n",
      "RMSE trên tập kiểm tra: 14.992203832506496\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import itertools\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes for Ridge\n",
    "ridge_best_score = -np.inf\n",
    "ridge_best_mse = np.inf\n",
    "ridge_best_params = {}\n",
    "ridge_results = []\n",
    "\n",
    "# Quá trình tuning tham số Ridge Regression\n",
    "for fit_intercept in param_grids['Ridge']['fit_intercept']:\n",
    "    for normalize in [True, False]:  # Giờ sử dụng chuẩn hóa với StandardScaler\n",
    "        # Sử dụng pipeline với StandardScaler và Ridge\n",
    "        if normalize:\n",
    "            ridge_model = make_pipeline(StandardScaler(), Ridge(fit_intercept=fit_intercept))\n",
    "        else:\n",
    "            ridge_model = Ridge(fit_intercept=fit_intercept)\n",
    "        \n",
    "        # Đánh giá mô hình với k-fold cross-validation\n",
    "        scores = cross_validate_regression(ridge_model, X_train, y_train, k=5)\n",
    "        \n",
    "        avg_r2 = scores['r2']\n",
    "        avg_mse = scores['mse']\n",
    "        \n",
    "        # Lưu kết quả vào danh sách\n",
    "        ridge_results.append({\n",
    "            'fit_intercept': fit_intercept,\n",
    "            'normalize': normalize,\n",
    "            'R2': avg_r2,\n",
    "            'MSE': avg_mse\n",
    "        })\n",
    "        \n",
    "        # Cập nhật tham số tốt nhất\n",
    "        if avg_r2 > ridge_best_score and avg_mse < ridge_best_mse:\n",
    "            ridge_best_score = avg_r2\n",
    "            ridge_best_mse = avg_mse\n",
    "            ridge_best_params = {\n",
    "                'fit_intercept': fit_intercept,\n",
    "                'normalize': normalize\n",
    "            }\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll Ridge parameter tuning results:\")\n",
    "for result in ridge_results:\n",
    "    print(f\"fit_intercept = {result['fit_intercept']}, normalize = {result['normalize']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning Ridge Completed!\")\n",
    "print(f\"Best parameter: {ridge_best_params}\")\n",
    "print(f\"Best R^2: {ridge_best_score}\")\n",
    "print(f\"Best MSE: {ridge_best_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "if ridge_best_params['normalize']:\n",
    "    ridge_best_model = make_pipeline(StandardScaler(), Ridge(fit_intercept=ridge_best_params['fit_intercept']))\n",
    "else:\n",
    "    ridge_best_model = Ridge(fit_intercept=ridge_best_params['fit_intercept'])\n",
    "\n",
    "ridge_best_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "ridge_y_pred_test = ridge_best_model.predict(X_test)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_y_pred_test)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_y_pred_test)\n",
    "ridge_test_rmse = np.sqrt(ridge_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nRidge Test Results:\")\n",
    "print(f\"R^2: {ridge_test_r2}\")\n",
    "print(f\"MSE: {ridge_test_mse}\")\n",
    "print(f\"RMSE: {ridge_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes\n",
    "lasso_best_score = -np.inf\n",
    "lasso_best_mse = np.inf\n",
    "lasso_best_params = {}\n",
    "lasso_results = []\n",
    "\n",
    "# Fine-tuning Lasso Regression\n",
    "for alpha in param_grids['Lasso']['alpha']:\n",
    "    # Sử dụng pipeline với StandardScaler và Lasso\n",
    "    model = make_pipeline(StandardScaler(), Lasso(alpha=alpha, random_state=18))\n",
    "    \n",
    "    # Đánh giá mô hình với k-fold cross-validation\n",
    "    scores = cross_validate_regression(model, X_train, y_train, k=5)\n",
    "    \n",
    "    avg_r2 = scores['r2']\n",
    "    avg_mse = scores['mse']\n",
    "    \n",
    "    # Lưu kết quả vào danh sách\n",
    "    lasso_results.append({\n",
    "        'alpha': alpha,\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    })\n",
    "    \n",
    "    # Cập nhật tham số tốt nhất\n",
    "    if avg_r2 > lasso_best_score and avg_mse < lasso_best_mse:\n",
    "        lasso_best_score = avg_r2\n",
    "        lasso_best_mse = avg_mse\n",
    "        lasso_best_params = {'alpha': alpha}\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll Lasso parameter tuning results:\")\n",
    "for result in lasso_results:\n",
    "    print(f\"alpha = {result['alpha']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning Lasso Completed!\")\n",
    "print(f\"Best parameter: {lasso_best_params}\")\n",
    "print(f\"Best R^2: {lasso_best_score}\")\n",
    "print(f\"Best MSE: {lasso_best_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "best_lasso_model = make_pipeline(StandardScaler(), Lasso(alpha=lasso_best_params['alpha'], random_state=18))\n",
    "best_lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "lasso_y_pred_test = best_lasso_model.predict(X_test)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_y_pred_test)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_y_pred_test)\n",
    "lasso_test_rmse = np.sqrt(lasso_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nLasso Test Results:\")\n",
    "print(f\"R^2: {lasso_test_r2}\")\n",
    "print(f\"MSE: {lasso_test_mse}\")\n",
    "print(f\"RMSE: {lasso_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Initialize variables to store the best results and all tuning outcomes\n",
    "best_svr_score = -np.inf\n",
    "best_svr_mse = np.inf\n",
    "best_svr_params = {}\n",
    "svr_results = []\n",
    "\n",
    "# Fine-tuning SVR with max_iter included\n",
    "for C, kernel, epsilon, max_iter in itertools.product(\n",
    "    param_grids['SVR']['C'],\n",
    "    param_grids['SVR']['kernel'],\n",
    "    param_grids['SVR']['epsilon'],\n",
    "    param_grids['SVR']['max_iter']  \n",
    "):\n",
    "    # Sử dụng pipeline với StandardScaler và SVR\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVR(C=C, kernel=kernel, epsilon=epsilon, max_iter=max_iter)\n",
    "    )\n",
    "    # Đánh giá mô hình với k-fold cross-validation\n",
    "    scores = cross_validate_regression(model, X_train, y_train, k=5)\n",
    "    \n",
    "    avg_r2 = scores['r2']\n",
    "    avg_mse = scores['mse']\n",
    "    \n",
    "    # Lưu kết quả vào danh sách\n",
    "    svr_results.append({\n",
    "        'C': C,\n",
    "        'kernel': kernel,\n",
    "        'epsilon': epsilon,\n",
    "        'max_iter': max_iter,\n",
    "        'R2': avg_r2,\n",
    "        'MSE': avg_mse\n",
    "    })\n",
    "    \n",
    "    # Cập nhật tham số tốt nhất\n",
    "    if avg_r2 > best_svr_score and avg_mse < best_svr_mse:\n",
    "        best_svr_score = avg_r2\n",
    "        best_svr_mse = avg_mse\n",
    "        best_svr_params = {\n",
    "            'C': C,\n",
    "            'kernel': kernel,\n",
    "            'epsilon': epsilon,\n",
    "            'max_iter': max_iter\n",
    "        }\n",
    "\n",
    "# In tất cả các kết quả tuning\n",
    "print(\"\\nAll SVR parameter tuning results:\")\n",
    "for result in svr_results:\n",
    "    print(f\"C = {result['C']}, kernel = {result['kernel']}, epsilon = {result['epsilon']}, max_iter = {result['max_iter']}, R^2 = {result['R2']}, MSE = {result['MSE']}\")\n",
    "\n",
    "# In báo cáo quá trình tuning\n",
    "print(\"\\nFine-Tuning SVR Completed!\")\n",
    "print(f\"Best parameter: {best_svr_params}\")\n",
    "print(f\"Best R^2: {best_svr_score}\")\n",
    "print(f\"Best MSE: {best_svr_mse}\")\n",
    "\n",
    "# Huấn luyện lại mô hình với tham số tốt nhất trên toàn bộ tập huấn luyện\n",
    "best_svr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(\n",
    "        C=best_svr_params['C'],\n",
    "        kernel=best_svr_params['kernel'],\n",
    "        epsilon=best_svr_params['epsilon'],\n",
    "        max_iter=best_svr_params['max_iter']\n",
    "    )\n",
    ")\n",
    "\n",
    "best_svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và tính toán các chỉ số R², MSE, RMSE\n",
    "svr_y_pred_test = best_svr_model.predict(X_test)\n",
    "svr_test_r2 = r2_score(y_test, svr_y_pred_test)\n",
    "svr_test_mse = mean_squared_error(y_test, svr_y_pred_test)\n",
    "svr_test_rmse = np.sqrt(svr_test_mse)\n",
    "\n",
    "# In kết quả trên tập kiểm tra\n",
    "print(\"\\nSVR Test Results:\")\n",
    "print(f\"R^2: {svr_test_r2}\")\n",
    "print(f\"MSE: {svr_test_mse}\")\n",
    "print(f\"RMSE: {svr_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Lưu các kết quả của 3 mô hình vào một dictionary\n",
    "results = {\n",
    "    'Model': ['Ridge', 'Lasso', 'SVR'],\n",
    "    'R²': [ridge_test_r2, lasso_test_r2, svr_test_r2],\n",
    "    'MSE': [ridge_test_mse, lasso_test_mse, svr_test_mse],\n",
    "    'RMSE': [ridge_test_rmse, lasso_test_rmse, svr_test_rmse]\n",
    "}\n",
    "\n",
    "# Chọn mô hình tốt nhất (Dựa trên MSE hoặc R² cao nhất)\n",
    "best_model_index = np.argmin(results['MSE'])  # Chọn mô hình có MSE thấp nhất\n",
    "best_model_name = results['Model'][best_model_index]\n",
    "best_model_r2 = results['R²'][best_model_index]\n",
    "best_model_mse = results['MSE'][best_model_index]\n",
    "best_model_rmse = results['RMSE'][best_model_index]\n",
    "\n",
    "# In kết quả mô hình tốt nhất\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best Model R²: {best_model_r2}\")\n",
    "print(f\"Best Model MSE: {best_model_mse}\")\n",
    "print(f\"Best Model RMSE: {best_model_rmse}\")\n",
    "\n",
    "# Vẽ biểu đồ so sánh MSE, RMSE và R² của các mô hình\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Biểu đồ MSE\n",
    "sns.barplot(x=results['Model'], y=results['MSE'], ax=ax[0])\n",
    "ax[0].set_title('Mean Squared Error (MSE)')\n",
    "ax[0].set_xlabel('Model')\n",
    "ax[0].set_ylabel('MSE')\n",
    "\n",
    "# Biểu đồ RMSE\n",
    "sns.barplot(x=results['Model'], y=results['RMSE'], ax=ax[1])\n",
    "ax[1].set_title('Root Mean Squared Error (RMSE)')\n",
    "ax[1].set_xlabel('Model')\n",
    "ax[1].set_ylabel('RMSE')\n",
    "\n",
    "# Biểu đồ R²\n",
    "sns.barplot(x=results['Model'], y=results['R²'], ax=ax[2])\n",
    "ax[2].set_title('R² Score')\n",
    "ax[2].set_xlabel('Model')\n",
    "ax[2].set_ylabel('R²')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In bảng kết quả để so sánh\n",
    "print(\"\\nComparison of Models:\")\n",
    "for model, mse, rmse, r2 in zip(results['Model'], results['MSE'], results['RMSE'], results['R²']):\n",
    "    print(f\"{model} - MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In công thức của mô hình tốt nhất\n",
    "if best_model_name == 'Ridge':\n",
    "    coefficients = ridge_best_model.coef_\n",
    "    intercept = ridge_best_model.intercept_\n",
    "    formula = f\"y = {intercept:.4f}\"\n",
    "    for i, coef in enumerate(coefficients):\n",
    "        formula += f\" + ({coef:.4f}) * {X_train.columns[i]}\"\n",
    "    print(f\"Formula of model Ridge: {formula}\")\n",
    "\n",
    "elif best_model_name == 'Lasso':\n",
    "    coefficients = best_lasso_model.coef_\n",
    "    intercept = best_lasso_model.intercept_\n",
    "    formula = f\"y = {intercept:.4f}\"\n",
    "    for i, coef in enumerate(coefficients):\n",
    "        formula += f\" + ({coef:.4f}) * {X_train.columns[i]}\"\n",
    "    print(f\"Formula of model Lasso: {formula}\")\n",
    "\n",
    "elif best_model_name == 'SVR':\n",
    "    print(f\"Information of model SVR:\")\n",
    "    print(f\"C (Regularization parameter): {best_svr_model.C}\")\n",
    "    print(f\"epsilon (Margin of tolerance): {best_svr_model.epsilon}\")\n",
    "    print(f\"Number of support vectors: {len(best_svr_model.support_)}\")\n",
    "    print(f\"Support vectors: {best_svr_model.support_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
